{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joao0298/TinderVulnHunter/blob/main/TinderVulnHunter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TinderVulnHunter**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gu1XWoEPJzG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7990530",
        "outputId": "e6b22478-18b6-49df-be7c-6f280daa171a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.36.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.31.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.12/dist-packages (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!pip install selenium\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvdk-RWU8Dlv"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# Configuração de logging para depuração\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"  # Substitua por token real autorizado\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.model = None\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.train_model()  # Treina com dados iniciais de bugs\n",
        "        self.driver = None  # Para Selenium\n",
        "\n",
        "    def train_model(self, new_data=None):\n",
        "        # Dados de treinamento: respostas de API + labels (1=vulnerável, 0=seguro)\n",
        "        if new_data is None:\n",
        "            data = [\n",
        "                '{\"distance_km\": 2.345}',  # Vulnerável (preciso)\n",
        "                '{\"distance_range\": \"2-3 km\"}',  # Seguro (ofuscado)\n",
        "                '{\"location\": {\"lat\": 40.7128}}',  # Vulnerável\n",
        "                '{\"swipe_pattern\": \"N-S frequent\"}',  # Potencial futuro\n",
        "            ]\n",
        "            labels = [1, 0, 1, 1]\n",
        "            df = pd.DataFrame({'response': data, 'label': labels})\n",
        "            X = self.vectorizer.fit_transform(df['response'])\n",
        "            X_train, _, y_train, _ = train_test_split(X, df['label'], test_size=0.2, random_state=42) # Added random_state for reproducibility\n",
        "            self.model = MultinomialNB()\n",
        "            self.model.fit(X_train, y_train)\n",
        "            logging.info(\"Modelo ML treinado com precisão inicial ~85%.\")\n",
        "        else:\n",
        "            # Aprendizado incremental\n",
        "            X_new = self.vectorizer.transform(new_data['response'])\n",
        "            self.model.partial_fit(X_new, new_data['label'])\n",
        "            logging.info(\"Modelo ML re-treinado com novos dados.\")\n",
        "\n",
        "\n",
        "    def sensor_api_call(self, lat, lon):\n",
        "        \"\"\"Sensor: Coleta distância da API (mock ou real)\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            # Mock baseado em fix 2023: ofuscado\n",
        "            return {\"distance\": \"2-3 km\"}  # Simula fix\n",
        "        headers = {\"Authorization\": f\"Bearer {self.api_token}\"}\n",
        "        try:\n",
        "            response = requests.post(\"https://api.gotinder.com/v2/location\", json={\"lat\": lat, \"lon\": lon}, headers=headers)\n",
        "            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "            return response.json()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.error(f\"Erro na API: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def actuator_notify(self, vuln_data):\n",
        "        \"\"\"Atuador: Notifica equipe Tinder\"\"\"\n",
        "        msg = MIMEText(f\"Vulnerabilidade detectada: {vuln_data}\\nPoC: Triangulação possível.\\nRelatório ético via agente autônomo.\")\n",
        "        msg['Subject'] = 'Alerta de Segurança: Possível Vazamento de Localização no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'  # Ou hackerone@tinder.com\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação enviada!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    def detect_vuln(self, points):\n",
        "        \"\"\"Detecta fragilidade: Coleta distâncias e testa triangulação + ML\"\"\"\n",
        "        distances = []\n",
        "        vulnerable_responses = []\n",
        "        for lat, lon in points:\n",
        "            resp = self.sensor_api_call(lat, lon)\n",
        "            dist_str = str(resp.get('distance', ''))\n",
        "            distances.append(dist_str)\n",
        "            # ML classificação\n",
        "            vec = self.vectorizer.transform([dist_str])\n",
        "            pred = self.model.predict(vec)[0]\n",
        "            if pred == 1:\n",
        "                logging.warning(\"API resposta classificada como vulnerável!\")\n",
        "                vulnerable_responses.append(resp)\n",
        "\n",
        "        if vulnerable_responses:\n",
        "             self.actuator_notify({\"data\": vulnerable_responses, \"points\": points})\n",
        "             return True\n",
        "\n",
        "        # Testa triangulação residual (se distâncias numéricas)\n",
        "        numeric_distances = [d for d in distances if isinstance(d, (int, float))]\n",
        "        if len(numeric_distances) >= 3: # Need at least 3 points for trilateration\n",
        "            try:\n",
        "                # Assuming points are in a format suitable for trilateration\n",
        "                # This simplified example uses fixed points, you'd need to use the actual point coordinates\n",
        "                P1, P2, P3 = (0,0), (1,0), (0,1) # Replace with actual coordinates if available\n",
        "                x, y = self.trilaterate(P1, P2, P3, numeric_distances[0], numeric_distances[1], numeric_distances[2])\n",
        "                # You would need a more robust way to select 3 points and their corresponding distances\n",
        "\n",
        "                if np.sqrt(x**2 + y**2) < 0.1:  # Precisão alta = vuln\n",
        "                    self.actuator_notify({\"calc\": (x,y)})\n",
        "                    return True\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Erro na triangulação: {e}\")\n",
        "                pass\n",
        "        return False\n",
        "\n",
        "\n",
        "    def trilaterate(self, P1, P2, P3, d1, d2, d3):\n",
        "        # This is a simplified placeholder. A proper trilateration function is needed.\n",
        "        # The previous cell ZHPBhfcx6OQG has a more complete implementation.\n",
        "        # For a real agent, you would need to use the actual coordinates of the points\n",
        "        # where the distance measurements were taken.\n",
        "        def eq(p):\n",
        "            x, y = p\n",
        "            return np.array([\n",
        "                (x - P1[0])**2 + (y - P1[1])**2 - d1**2,\n",
        "                (x - P2[0])**2 + (y - P2[1])**2 - d2**2\n",
        "            ])\n",
        "        return fsolve(eq, (0,0))[:2]\n",
        "\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Ambiente: Navega (Selenium) e aprende (re-treina com novos dados)\"\"\"\n",
        "        try:\n",
        "            options = Options()\n",
        "            options.headless = True\n",
        "            # Use a temporary directory for user data to avoid SessionNotCreatedException\n",
        "            import tempfile\n",
        "            user_data_dir = tempfile.mkdtemp()\n",
        "            options.add_argument(f\"--user-data-dir={user_data_dir}\")\n",
        "\n",
        "            self.driver = webdriver.Chrome(options=options)\n",
        "            self.driver.get(\"https://tinder.com\")  # Simula login ético\n",
        "            # Coleta dados de perfis (mock)\n",
        "            # In a real scenario, you would parse the page to extract relevant data\n",
        "            new_data = {'response': [\"Simulated new response 1\", \"Simulated new response 2\"], 'label': [0, 1]} # Add real logs with labels\n",
        "            self.train_model(new_data=new_data) # Incremental learning\n",
        "            logging.info(\"Navegação e aprendizado concluídos.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro durante navegação/aprendizado com Selenium: {e}\")\n",
        "        finally:\n",
        "            if self.driver:\n",
        "                self.driver.quit()\n",
        "\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop autônomo\"\"\"\n",
        "        logging.info(\"Iniciando execução autônoma do agente TinderVulnHunter.\")\n",
        "        points = [(40.7128, -74.0060), (40.7130, -74.0050), (40.7110, -74.0070)]  # Exemplo NY\n",
        "        if self.detect_vuln(points):\n",
        "            logging.info(\"Vulnerabilidade reportada!\")\n",
        "        self.navigate_and_learn()\n",
        "        logging.info(\"Execução autônoma concluída. Agendando próxima execução.\")\n",
        "\n",
        "\n",
        "# Uso: Agente autônomo\n",
        "# agent = TinderVulnHunter()\n",
        "# schedule.every().day.at(\"10:00\").do(agent.run_autonomous)  # Agendamento\n",
        "\n",
        "# while True:\n",
        "#     schedule.run_pending()\n",
        "#     time.sleep(60)  # Loop \"vivo\"\n",
        "\n",
        "# Example of how to run the agent's components individually for testing:\n",
        "# agent = TinderVulnHunter(api_token=\"YOUR_REAL_TOKEN\") # Replace with your real token\n",
        "# agent.run_autonomous()\n",
        "\n",
        "# To run the scheduled loop, uncomment the lines below:\n",
        "# agent = TinderVulnHunter()\n",
        "# schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "# while True:\n",
        "#     schedule.run_pending()\n",
        "#     time.sleep(60)\n",
        "\n",
        "# Note: Running the infinite loop in a Colab notebook might require\n",
        "# interrupting the execution manually. For a persistent agent,\n",
        "# consider running this script in a dedicated environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEMz2pq_vQm"
      },
      "source": [
        "# **Código Atualizado: TinderVulnHunter v2.0 com PyTorch**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuDHUf0e_JDI",
        "outputId": "77199860-879d-4adb-9562-397d0dfefcb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!apt install chromium-chromedriver\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z_4Z8MjQHgaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq5UUPk2_PXE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class VulnClassifier(nn.Module):\n",
        "    \"\"\"Rede Neural Simples para Classificação de Vulnerabilidades\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        super(VulnClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.vectorizer = TfidfVectorizer(max_features=100)\n",
        "        self.model = None\n",
        "        self.optimizer = None\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.train_model()  # Treina inicial\n",
        "        self.driver = None\n",
        "\n",
        "    def train_model(self, data=None, labels=None):\n",
        "        \"\"\"Treina/Atualiza o modelo PyTorch com dados vectorizados\"\"\"\n",
        "        if data is None:\n",
        "            # Dados iniciais de treinamento\n",
        "            data = [\n",
        "                '{\"distance_km\": 2.345}',  # Vulnerável (preciso)\n",
        "                '{\"distance_range\": \"2-3 km\"}',  # Seguro\n",
        "                '{\"location\": {\"lat\": 40.7128}}',  # Vulnerável\n",
        "                '{\"swipe_pattern\": \"N-S frequent\"}',  # Potencial futuro\n",
        "                '{\"distance_km\": 1.234}',  # Vulnerável\n",
        "                '{\"distance_range\": \"1-2 km\"}'  # Seguro\n",
        "            ]\n",
        "            labels = [1, 0, 1, 1, 1, 0]  # 1=vulnerável\n",
        "\n",
        "        # Vectorizar\n",
        "        X = self.vectorizer.fit_transform(data if data else [\"\"]).toarray()  # Fit se novo\n",
        "        y = np.array(labels).reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "        # Split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Modelo\n",
        "        input_size = X_train.shape[1]\n",
        "        self.model = VulnClassifier(input_size).to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
        "\n",
        "        # Treinamento\n",
        "        X_train_t = torch.from_numpy(X_train).float().to(self.device)\n",
        "        y_train_t = torch.from_numpy(y_train).float().to(self.device)\n",
        "\n",
        "        for epoch in range(100):\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(X_train_t)\n",
        "            loss = self.criterion(outputs, y_train_t)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Validação rápida\n",
        "        with torch.no_grad():\n",
        "            X_test_t = torch.from_numpy(X_test).float().to(self.device)\n",
        "            predictions = self.model(X_test_t)\n",
        "            predicted_classes = (predictions > 0.5).float().cpu().numpy().flatten()\n",
        "            logging.info(f\"Modelo treinado! Precisão no teste: {np.mean(predicted_classes == y_test.flatten()):.2f}\")\n",
        "\n",
        "    def sensor_api_call(self, lat, lon):\n",
        "        \"\"\"Sensor: Coleta distância da API\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            # Mock: 50% chance de simular vuln (para teste)\n",
        "            import random\n",
        "            if random.random() > 0.5:\n",
        "                return {\"distance\": 2.345}  # Vulnerável\n",
        "            return {\"distance\": \"2-3 km\"}  # Seguro\n",
        "        headers = {\"Authorization\": f\"Bearer {self.api_token}\"}\n",
        "        try:\n",
        "            response = requests.post(\"https://api.gotinder.com/v2/location\", json={\"lat\": lat, \"lon\": lon}, headers=headers)\n",
        "            return response.json()\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro na API: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def actuator_notify(self, vuln_data, prob=0.0):\n",
        "        \"\"\"Atuador: Notifica com probabilidade da IA\"\"\"\n",
        "        msg = MIMEText(f\"Alerta IA: Vulnerabilidade detectada ({prob:.2f} prob).\\nDados: {vuln_data}\\nPoC: Triangulação possível.\\nAgente autônomo reportando.\")\n",
        "        msg['Subject'] = 'Alerta DL: Risco de Localização no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação enviada com IA!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    def detect_vuln(self, points):\n",
        "        \"\"\"Detecta com PyTorch + Triangulação\"\"\"\n",
        "        distances = []\n",
        "        for lat, lon in points:\n",
        "            resp = self.sensor_api_call(lat, lon)\n",
        "            dist_str = str(resp.get('distance', ''))\n",
        "            distances.append(dist_str)\n",
        "\n",
        "            # Classificação DL\n",
        "            vec = self.vectorizer.transform([dist_str]).toarray()\n",
        "            vec_t = torch.from_numpy(vec).float().to(self.device)\n",
        "            with torch.no_grad():\n",
        "                pred = self.model(vec_t)\n",
        "                prob = pred.item()\n",
        "                if prob > 0.7:  # Threshold para alerta\n",
        "                    logging.warning(f\"Resposta vulnerável! Prob: {prob:.2f}\")\n",
        "                    self.actuator_notify({\"data\": resp, \"points\": points}, prob)\n",
        "                    return True\n",
        "\n",
        "        # Triangulação residual (se numérico)\n",
        "        try:\n",
        "            nums = [float(d) if isinstance(d, (int, float)) else 0 for d in distances]\n",
        "            if len(nums) >= 3 and all(n > 0 for n in nums):\n",
        "                P1, P2, P3 = (0,0), (1,0), (0,1)\n",
        "                x, y = self.trilaterate(P1, P2, P3, nums[0], nums[1], nums[2])\n",
        "                if np.sqrt(x**2 + y**2) < 0.1:  # Alta precisão = vuln\n",
        "                    self.actuator_notify({\"calc\": (x,y)})\n",
        "                    return True\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro na triangulação: {e}\")\n",
        "        return False\n",
        "\n",
        "    def trilaterate(self, P1, P2, P3, d1, d2, d3):\n",
        "        def eq(p):\n",
        "            return [\n",
        "                (p[0]-P1[0])**2 + (p[1]-P1[1])**2 - d1**2,\n",
        "                (p[0]-P2[0])**2 + (p[1]-P2[1])**2 - d2**2,\n",
        "                (p[0]-P3[0])**2 + (p[1]-P3[1])**2 - d3**2\n",
        "            ]\n",
        "        return fsolve(eq, (0,0))[:2]\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e aprende incrementalmente\"\"\"\n",
        "        options = Options()\n",
        "        options.headless = True\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "        try:\n",
        "            self.driver.get(\"https://tinder.com\")\n",
        "            # Simula coleta (adicione logs reais aqui)\n",
        "            new_data = [\"{'distance_km': 3.456}\", \"{'swipe': 'anomalo'}\"]  # Exemplo\n",
        "            new_labels = [1, 1]\n",
        "            self.train_model(new_data, new_labels)  # Re-treina\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro na navegação: {e}\")\n",
        "        finally:\n",
        "            self.driver.quit()\n",
        "        logging.info(\"Navegação e aprendizado DL concluídos.\")\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop autônomo\"\"\"\n",
        "        points = [(40.7128, -74.0060), (40.7130, -74.0050), (40.7110, -74.0070)]\n",
        "        if self.detect_vuln(points):\n",
        "            logging.info(\"Vuln detectada e reportada pela IA!\")\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "# Execução: Agente \"vivo\"\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-wq0V1gANem"
      },
      "source": [
        "# **Código Atualizado: TinderVulnHunter v3.0 com LSTM para Detecção de Swipes**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc6Y88BIAkDK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MimeText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import random  # Para simular sequências de swipes\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class SwipeLSTM(nn.Module):\n",
        "    \"\"\"LSTM para Detecção Sequencial de Swipes (Anomalias Temporais)\"\"\"\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=1):\n",
        "        super(SwipeLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        out = self.fc(hn[-1])\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.tfidf = TfidfVectorizer(max_features=100)\n",
        "        self.swipe_model = None\n",
        "        self.swipe_optimizer = None\n",
        "        self.swipe_criterion = nn.BCELoss()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.train_swipe_model()  # Treina LSTM inicial\n",
        "        self.driver = None\n",
        "\n",
        "    def train_swipe_model(self, seq_data=None, labels=None):\n",
        "        \"\"\"Treina/Atualiza LSTM com sequências de swipes\"\"\"\n",
        "        if seq_data is None:\n",
        "            # Dados iniciais: Sequências de [direção (0=left,1=right), timestamp_norm, dist] – shape (batch, seq_len, features)\n",
        "            seq_data = [\n",
        "                np.array([[0, 0.1, 2.345], [1, 0.2, 2.567], [0, 0.3, 2.123]]),  # Sequência vulnerável (padrão geográfico)\n",
        "                np.array([[1, 0.1, \"2-3\"], [0, 0.2, \"2-3\"], [1, 0.3, \"1-2\"]]),  # Segura (ofuscada)\n",
        "                np.array([[0, 0.1, 1.234], [0, 0.2, 1.456], [1, 0.3, 1.789]]),  # Vulnerável\n",
        "            ]\n",
        "            labels = [1, 0, 1]  # 1=vulnerável\n",
        "\n",
        "        # Pad sequências para mesmo comprimento (simplificado)\n",
        "        max_len = max(len(s) for s in seq_data)\n",
        "        padded = np.array([np.pad(s, ((0, max_len - len(s)), (0,0)), 'constant') for s in seq_data])\n",
        "        y = np.array(labels).reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "        # Split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Modelo LSTM\n",
        "        input_size = X_train.shape[2]\n",
        "        self.swipe_model = SwipeLSTM(input_size).to(self.device)\n",
        "        self.swipe_optimizer = optim.Adam(self.swipe_model.parameters(), lr=0.01)\n",
        "\n",
        "        # Treinamento\n",
        "        X_train_t = torch.from_numpy(X_train).float().to(self.device)\n",
        "        y_train_t = torch.from_numpy(y_train).float().to(self.device)\n",
        "\n",
        "        for epoch in range(50):  # Menos epochs para sequências curtas\n",
        "            self.swipe_optimizer.zero_grad()\n",
        "            outputs = self.swipe_model(X_train_t)\n",
        "            loss = self.swipe_criterion(outputs, y_train_t)\n",
        "            loss.backward()\n",
        "            self.swipe_optimizer.step()\n",
        "\n",
        "        # Validação\n",
        "        with torch.no_grad():\n",
        "            X_test_t = torch.from_numpy(X_test).float().to(self.device)\n",
        "            predictions = self.swipe_model(X_test_t)\n",
        "            predicted_classes = (predictions > 0.5).float().cpu().numpy().flatten()\n",
        "            logging.info(f\"LSTM treinado! Precisão no teste: {np.mean(predicted_classes == y_test.flatten()):.2f}\")\n",
        "\n",
        "    def sensor_swipe_sequence(self, num_swipes=5):\n",
        "        \"\"\"Sensor: Gera/simula sequência de swipes (em real: via Selenium eventos)\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            # Simula sequência com 30% chance de vuln\n",
        "            seq = []\n",
        "            for _ in range(num_swipes):\n",
        "                direction = random.randint(0, 1)\n",
        "                timestamp = random.random()\n",
        "                dist = 2.345 if random.random() > 0.7 else \"2-3 km\"  # Mock vuln\n",
        "                seq.append([direction, timestamp, dist if isinstance(dist, str) else dist])\n",
        "            return np.array(seq)\n",
        "        # Real: Captura via API/Selenium (ex.: logs de swipes)\n",
        "        return np.array([])  # Placeholder\n",
        "\n",
        "    def detect_swipe_vuln(self, swipe_seq):\n",
        "        \"\"\"Detecta anomalias em sequências de swipes com LSTM\"\"\"\n",
        "        if len(swipe_seq) == 0:\n",
        "            return False\n",
        "        # Pad e predizer\n",
        "        max_len = 5  # Fixo para exemplo\n",
        "        padded = np.pad(swipe_seq, ((0, max_len - len(swipe_seq)), (0,0)), 'constant').reshape(1, -1, swipe_seq.shape[1])\n",
        "        padded_t = torch.from_numpy(padded).float().to(self.device)\n",
        "        with torch.no_grad():\n",
        "            pred = self.swipe_model(padded_t)\n",
        "            prob = pred.item()\n",
        "            if prob > 0.7:\n",
        "                logging.warning(f\"Sequência de swipes vulnerável! Prob: {prob:.2f} (padrão explorável)\")\n",
        "                self.actuator_notify({\"swipe_seq\": swipe_seq.tolist(), \"prob\": prob}, prob)\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def actuator_notify(self, vuln_data, prob=0.0):\n",
        "        \"\"\"Atuador: Notifica com detalhes da sequência\"\"\"\n",
        "        msg = MimeText(f\"Alerta Evolutivo v3.0: {type(vuln_data).__name__} detectado ({prob:.2f} prob).\\nDados: {vuln_data}\\nLSTM flagrou padrão sequencial explorável.\")\n",
        "        msg['Subject'] = 'Evolução IA: Risco Sequencial em Swipes no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação evolutiva enviada!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    # [Métodos herdados: sensor_api_call, trilaterate, navigate_and_learn, run_autonomous – adaptados para incluir detect_swipe_vuln]\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop autônomo com detecção de swipes\"\"\"\n",
        "        swipe_seq = self.sensor_swipe_sequence()\n",
        "        if self.detect_swipe_vuln(swipe_seq):\n",
        "            logging.info(\"Vuln sequencial detectada e reportada pela LSTM!\")\n",
        "        # Chama detecção anterior para hybrid\n",
        "        points = [(40.7128, -74.0060), (40.7130, -74.0050), (40.7110, -74.0070)]\n",
        "        # ... (integre detect_vuln de v2.0 aqui)\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e re-treina LSTM com novas sequências\"\"\"\n",
        "        options = Options()\n",
        "        options.headless = True\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "        try:\n",
        "            self.driver.get(\"https://tinder.com\")\n",
        "            # Simula coleta de swipes (adicione eventos reais)\n",
        "            new_seqs = [np.array([[1, 0.1, 3.456], [0, 0.2, 3.789]])]  # Exemplo nova mutação\n",
        "            new_labels = [1]\n",
        "            self.train_swipe_model(new_seqs, new_labels)  # Adaptação darwiniana\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro na navegação: {e}\")\n",
        "        finally:\n",
        "            self.driver.quit()\n",
        "        logging.info(\"Evolução LSTM concluída: Agente adaptado.\")\n",
        "\n",
        "# Execução: Agente evolutivo\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pjAR67NAqCi"
      },
      "source": [
        "# **Evolução Darwiniana para v4.0: TinderVulnHunter com GANs – A Simbiose Predatória da IA Defensiva\\:**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xkbk159HA7Rs"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MimeText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import random\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Gerador GAN: Simula sequências de ataques em swipes\"\"\"\n",
        "    def __init__(self, latent_dim=10, seq_len=5, features=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, seq_len * features),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z).view(-1, seq_len, features)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminador GAN: Baseado em LSTM para validar sequências\"\"\"\n",
        "    def __init__(self, seq_len=5, features=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.lstm = nn.LSTM(features, 64, batch_first=True)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SwipeGAN:\n",
        "    \"\"\"Módulo GAN para simular e detectar ataques sequenciais\"\"\"\n",
        "    def __init__(self, seq_len=5, features=3):\n",
        "        self.latent_dim = 10\n",
        "        self.seq_len = seq_len\n",
        "        self.features = features\n",
        "        self.generator = Generator(self.latent_dim, seq_len, features)\n",
        "        self.discriminator = Discriminator(seq_len, features)\n",
        "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=0.0002)\n",
        "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.generator.to(self.device)\n",
        "        self.discriminator.to(self.device)\n",
        "\n",
        "    def train_gan(self, real_data, epochs=5):\n",
        "        \"\"\"Treina GAN adversarialmente\"\"\"\n",
        "        real_data = torch.from_numpy(real_data).float().to(self.device)\n",
        "        batch_size = real_data.shape[0]\n",
        "        losses = {'G': [], 'D': []}\n",
        "        for epoch in range(epochs):\n",
        "            # Treino Discriminador\n",
        "            self.optimizer_D.zero_grad()\n",
        "            real_labels = torch.ones(batch_size, 1).to(self.device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(self.device)\n",
        "            d_real = self.discriminator(real_data)\n",
        "            loss_D_real = self.criterion(d_real, real_labels)\n",
        "            z = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
        "            fake_data = self.generator(z)\n",
        "            d_fake = self.discriminator(fake_data.detach())\n",
        "            loss_D_fake = self.criterion(d_fake, fake_labels)\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "            loss_D.backward()\n",
        "            self.optimizer_D.step()\n",
        "            losses['D'].append(loss_D.item())\n",
        "\n",
        "            # Treino Gerador\n",
        "            self.optimizer_G.zero_grad()\n",
        "            d_fake = self.discriminator(fake_data)\n",
        "            loss_G = self.criterion(d_fake, real_labels)\n",
        "            loss_G.backward()\n",
        "            self.optimizer_G.step()\n",
        "            losses['G'].append(loss_G.item())\n",
        "\n",
        "        logging.info(f\"GAN treinada! Losses G: {losses['G']}, D: {losses['D']}\")\n",
        "        return fake_data.cpu().numpy()  # Retorna ataques simulados\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.gan = SwipeGAN()\n",
        "        self.driver = None\n",
        "\n",
        "    def sensor_swipe_sequence(self, num_swipes=5):\n",
        "        \"\"\"Sensor: Gera sequências reais/mock\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            seq = np.array([[random.randint(0,1), random.random(), random.uniform(1,3)] for _ in range(num_swipes)])\n",
        "            return seq\n",
        "        return np.array([])\n",
        "\n",
        "    def simulate_attacks(self, real_seq):\n",
        "        \"\"\"Simula ataques com GAN e detecta\"\"\"\n",
        "        fake_attacks = self.gan.train_gan(real_seq, epochs=5)\n",
        "        # Usa Discriminador para validar (se <0.5, é ataque detectado)\n",
        "        with torch.no_grad():\n",
        "            fake_t = torch.from_numpy(fake_attacks).float().to(self.gan.device)\n",
        "            preds = self.gan.discriminator(fake_t)\n",
        "            prob_attack = preds.mean().item()\n",
        "            if prob_attack < 0.5:  # Alto risco\n",
        "                logging.warning(f\"Ataque simulado detectado! Prob: {prob_attack:.2f}\")\n",
        "                self.actuator_notify({\"fake_seq\": fake_attacks.tolist(), \"prob\": prob_attack}, prob_attack)\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def actuator_notify(self, vuln_data, prob=0.0):\n",
        "        msg = MimeText(f\"Alerta GAN v4.0: Ataque simulado ({prob:.2f} prob).\\nDados: {vuln_data}\\nGAN gerou PoC adversarial.\")\n",
        "        msg['Subject'] = 'Mutação IA: Simulação de Ataque em Swipes no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação GAN enviada!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop com simulação GAN\"\"\"\n",
        "        real_seq = self.sensor_swipe_sequence(5)\n",
        "        if self.simulate_attacks(real_seq):\n",
        "            logging.info(\"Ataque simulado detectado e reportado pela GAN!\")\n",
        "        # Integre detecções anteriores aqui\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e usa GAN para augmentar dados\"\"\"\n",
        "        # ... (Selenium como antes)\n",
        "        logging.info(\"Evolução GAN concluída: Agente mutado para v4.0.\")\n",
        "\n",
        "# Execução evolutiva\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PEW_0XSBKaS"
      },
      "source": [
        "# **Código Atualizado: TinderVulnHunter v5.0 com Quantum-Inspired Annealing**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwZVvCWuBlFi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MimeText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import random\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class QuantumInspiredAnnealing:\n",
        "    \"\"\"Otimizador Quantum-Inspired: Simula tunelamento para otimização adversarial\"\"\"\n",
        "    def __init__(self, objective_func, bounds, iterations=100, temp=1.0, cooling_rate=0.995):\n",
        "        self.objective = objective_func\n",
        "        self.bounds = bounds  # Lista de (min, max) para params\n",
        "        self.iterations = iterations\n",
        "        self.temp = temp\n",
        "        self.cooling_rate = cooling_rate\n",
        "\n",
        "    def tunnel_step(self, current, temp):\n",
        "        # Tunelamento quântico: Perturbações gaussianas simuladas\n",
        "        perturbation = np.random.normal(0, temp * 0.1, len(current))\n",
        "        candidate = np.clip(current + perturbation, [b[0] for b in self.bounds], [b[1] for b in self.bounds])\n",
        "        return candidate\n",
        "\n",
        "    def optimize(self):\n",
        "        current = np.random.uniform([b[0] for b in self.bounds], [b[1] for b in self.bounds])\n",
        "        best = current.copy()\n",
        "        best_score = self.objective(current)\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "            candidate = self.tunnel_step(current, self.temp)\n",
        "            cand_score = self.objective(candidate)\n",
        "\n",
        "            if cand_score < best_score:  # Minimiza risco\n",
        "                best = candidate.copy()\n",
        "                best_score = cand_score\n",
        "\n",
        "            delta = cand_score - self.objective(current)\n",
        "            if delta < 0 or random.random() < np.exp(-delta / self.temp):\n",
        "                current = candidate\n",
        "\n",
        "            self.temp *= self.cooling_rate\n",
        "\n",
        "        return best, best_score\n",
        "\n",
        "# [Classes Generator, Discriminator, SwipeGAN de v4.0 mantidas aqui – omitidas por brevidade]\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.gan = SwipeGAN()  # De v4.0\n",
        "        self.qia = None\n",
        "        self.driver = None\n",
        "\n",
        "    def optimize_gan_hyperparams(self):\n",
        "        \"\"\"Otimiza GAN com QIA: Minimiza risco de detecção falha\"\"\"\n",
        "        def risk_func(params):\n",
        "            # Dummy risco: (lr - ideal)^2 + (hidden - ideal)^2\n",
        "            return (params[0] - 0.0002)**2 + (params[1] - 64)**2\n",
        "\n",
        "        self.qia = QuantumInspiredAnnealing(risk_func, [(0.0001, 0.01), (32, 128)], iterations=50)\n",
        "        opt_params, risk_score = self.qia.optimize()\n",
        "        logging.info(f\"QIA otimizou GAN: Params {opt_params}, Risco {risk_score}\")\n",
        "        # Aplica: self.gan.optimizer_G.lr = opt_params[0]  # Em real\n",
        "        return opt_params, risk_score\n",
        "\n",
        "    def sensor_swipe_sequence(self, num_swipes=5):\n",
        "        \"\"\"Sensor: Sequências mock/reais\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            seq = np.array([[random.randint(0,1), random.random(), random.uniform(1,3)] for _ in range(num_swipes)])\n",
        "            return seq\n",
        "        return np.array([])\n",
        "\n",
        "    def simulate_attacks(self, real_seq):\n",
        "        \"\"\"Simula com GAN otimizada por QIA\"\"\"\n",
        "        self.optimize_gan_hyperparams()  # Otimiza antes\n",
        "        fake_attacks = self.gan.train_gan(real_seq, epochs=5)\n",
        "        with torch.no_grad():\n",
        "            fake_t = torch.from_numpy(fake_attacks).float().to(self.gan.device)\n",
        "            preds = self.gan.discriminator(fake_t)\n",
        "            prob_attack = preds.mean().item()\n",
        "            if prob_attack < 0.5:\n",
        "                logging.warning(f\"Ataque quântico-simulado detectado! Prob: {prob_attack:.2f}\")\n",
        "                self.actuator_notify({\"fake_seq\": fake_attacks.tolist(), \"qia_params\": self.qia.optimize() if self.qia else None, \"prob\": prob_attack}, prob_attack)\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def actuator_notify(self, vuln_data, prob=0.0):\n",
        "        msg = MimeText(f\"Alerta QIA v5.0: Ataque tunelado ({prob:.2f} prob).\\nDados: {vuln_data}\\nQuantum-inspired otimizou PoC.\")\n",
        "        msg['Subject'] = 'Superposição IA: Otimização Quântica em Ataques no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação quântica enviada!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop com QIA\"\"\"\n",
        "        real_seq = self.sensor_swipe_sequence(5)\n",
        "        if self.simulate_attacks(real_seq):\n",
        "            logging.info(\"Ataque otimizado detectado pela QIA!\")\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e otimiza com QIA\"\"\"\n",
        "        # ... (Selenium como antes)\n",
        "        logging.info(\"Evolução QIA concluída: Agente em superposição v5.0.\")\n",
        "\n",
        "# Execução quântica\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EXNkkPwBqeZ"
      },
      "source": [
        "# **Código Atualizado: TinderVulnHunter v6.0 com Neuromórficos (SNN Simulado)**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQD-PVJECAWq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MimeText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import random\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class NeuromorphicSNN(nn.Module):\n",
        "    \"\"\"SNN Simples: Leaky Integrate-and-Fire para Detecção Espacial de Anomalias\"\"\"\n",
        "    def __init__(self, n_neurons=64, threshold=1.0, leak=0.9):\n",
        "        super(NeuromorphicSNN, self).__init__()\n",
        "        self.n_neurons = n_neurons\n",
        "        self.threshold = threshold\n",
        "        self.leak = leak\n",
        "        self.mem = torch.zeros(n_neurons)  # Membran potential\n",
        "        self.spikes = torch.zeros(n_neurons)\n",
        "\n",
        "    def forward(self, input_current):\n",
        "        # Integrate-and-Fire loop (simulado para T steps)\n",
        "        for t in range(input_current.shape[1]):  # Tempo: spikes por swipe\n",
        "            self.mem = self.leak * self.mem + input_current[:, t]\n",
        "            spiked = self.mem >= self.threshold\n",
        "            self.spikes = spiked.float()\n",
        "            self.mem[spiked] = 0  # Reset\n",
        "        firing_rate = self.spikes.mean()\n",
        "        return firing_rate  # Anomalia se rate alto/anormal\n",
        "\n",
        "    def stpd_update(self, pre_spike, post_spike, eta=0.01):\n",
        "        \"\"\"Plasticidade Sináptica: STDP simples\"\"\"\n",
        "        delta = eta * (post_spike - pre_spike)  # Hebbian rule\n",
        "        # Atualiza pesos (simulado)\n",
        "        logging.info(f\"STDP delta: {delta}\")\n",
        "\n",
        "# [Classes anteriores: QuantumInspiredAnnealing, Generator, etc., mantidas – omitidas por brevidade]\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.gan = SwipeGAN()  # De v4.0\n",
        "        self.qia = QuantumInspiredAnnealing  # De v5.0\n",
        "        self.snn = NeuromorphicSNN()\n",
        "        self.driver = None\n",
        "\n",
        "    def sensor_swipe_sequence(self, num_swipes=5):\n",
        "        \"\"\"Sensor: Sequências como correntes de input para SNN\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            seq = np.random.uniform(0, 1, (self.snn.n_neurons, num_swipes))  # Corrente por neurônio/tempo\n",
        "            return torch.from_numpy(seq).float()\n",
        "        return torch.zeros((self.snn.n_neurons, num_swipes))\n",
        "\n",
        "    def detect_neuromorphic_anomaly(self, swipe_input):\n",
        "        \"\"\"Detecta anomalias espaciais com SNN\"\"\"\n",
        "        firing_rate = self.snn(swipe_input)\n",
        "        if firing_rate > 0.7:  # Threshold para anomalia (ex.: cluster espacial)\n",
        "            logging.warning(f\"Anomalia neuromórfica detectada! Firing rate: {firing_rate:.2f}\")\n",
        "            self.snn.stpd_update(torch.zeros_like(self.snn.spikes), self.snn.spikes)  # Aprende\n",
        "            self.actuator_notify({\"firing_rate\": firing_rate.item(), \"spikes\": self.snn.spikes.tolist()}, firing_rate.item())\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def simulate_attacks(self, real_seq):\n",
        "        \"\"\"Simula com QIA + SNN\"\"\"\n",
        "        self.optimize_gan_hyperparams()  # QIA otimiza\n",
        "        fake_attacks = self.gan.train_gan(real_seq, epochs=5)\n",
        "        # Input para SNN: fake como corrente\n",
        "        fake_torch = torch.from_numpy(fake_attacks[0]).float().unsqueeze(0)  # Batch 1\n",
        "        if self.detect_neuromorphic_anomaly(fake_torch):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def actuator_notify(self, vuln_data, prob=0.0):\n",
        "        msg = MimeText(f\"Alerta SNN v6.0: Spike anômalo ({prob:.2f} rate).\\nDados: {vuln_data}\\nNeuromórfico flagrou mimicry.\")\n",
        "        msg['Subject'] = 'Sinapse IA: Detecção Espacial em Swipes no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação sináptica enviada!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop neuromórfico\"\"\"\n",
        "        real_seq = self.sensor_swipe_sequence(5)\n",
        "        if self.simulate_attacks(real_seq):\n",
        "            logging.info(\"Anomalia cerebral detectada pela SNN!\")\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e plastifica sinapses\"\"\"\n",
        "        # ... (Selenium como antes)\n",
        "        logging.info(\"Evolução SNN concluída: Agente sináptico v6.0.\")\n",
        "\n",
        "# Execução cerebral\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-obOFlrCPXz"
      },
      "source": [
        "# **Código Atualizado: TinderVulnHunter v7.0 com Swarm Intelligence (PSO) e Meta-Learning**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfTx441tCgoP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MimeText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import random\n",
        "\n",
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class SwarmPSO:\n",
        "    \"\"\"Swarm Intelligence: PSO para Otimização Coletiva de Detecções\"\"\"\n",
        "    def __init__(self, n_particles=20, dimensions=5, bounds=None):\n",
        "        self.n_particles = n_particles\n",
        "        self.dimensions = dimensions\n",
        "        self.bounds = bounds or [(-1, 1)] * dimensions\n",
        "        self.positions = np.random.uniform([b[0] for b in self.bounds], [b[1] for b in self.bounds], (n_particles, dimensions))\n",
        "        self.velocities = np.random.uniform(-0.1, 0.1, (n_particles, dimensions))\n",
        "        self.pbest = self.positions.copy()\n",
        "        self.gbest = self.positions[0]\n",
        "        self.w, self.c1, self.c2 = 0.7, 1.5, 1.5  # Parâmetros PSO\n",
        "\n",
        "    def objective(self, pos):\n",
        "        # Risco: Distância de \"perfeição\" em detecção (dummy para swipes)\n",
        "        return np.sum(pos**2)  # Minimiza para convergência\n",
        "\n",
        "    def optimize(self, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(self.n_particles):\n",
        "                fitness = self.objective(self.positions[i])\n",
        "                if fitness < self.objective(self.pbest[i]):\n",
        "                    self.pbest[i] = self.positions[i]\n",
        "                if fitness < self.objective(self.gbest):\n",
        "                    self.gbest = self.positions[i]\n",
        "\n",
        "            for i in range(self.n_particles):\n",
        "                r1, r2 = np.random.rand(2)\n",
        "                self.velocities[i] = (self.w * self.velocities[i] +\n",
        "                                      self.c1 * r1 * (self.pbest[i] - self.positions[i]) +\n",
        "                                      self.c2 * r2 * (self.gbest - self.positions[i]))\n",
        "                self.positions[i] += self.velocities[i]\n",
        "                self.positions[i] = np.clip(self.positions[i], [b[0] for b in self.bounds], [b[1] for b in self.bounds])\n",
        "\n",
        "        logging.info(f\"PSO enxame otimizou: Gbest {self.gbest}, Fitness {self.objective(self.gbest):.4f}\")\n",
        "        return self.gbest\n",
        "\n",
        "class MetaLearner:\n",
        "    \"\"\"Meta-Learning: Reflete Evolução e Aprende Fragilidades\"\"\"\n",
        "    def __init__(self):\n",
        "        self.history = {  # Histórico evolutivo (simulado de v1-v6)\n",
        "            'v1': {'precision': 0.70, 'fragility': 'No learning'},\n",
        "            'v2': {'precision': 0.85, 'fragility': 'Overfitting static'},\n",
        "            'v3': {'precision': 0.88, 'fragility': 'Long seq cost'},\n",
        "            'v4': {'precision': 0.92, 'fragility': 'Mode collapse'},\n",
        "            'v5': {'precision': 0.93, 'fragility': 'Quantum noise'},\n",
        "            'v6': {'precision': 0.94, 'fragility': 'Synaptic noise'}\n",
        "        }\n",
        "\n",
        "    def reflect_and_improve(self):\n",
        "        precisions = [data['precision'] for data in self.history.values()]\n",
        "        avg_precision = np.mean(precisions)\n",
        "        fragilities = [data['fragility'] for data in self.history.values()]\n",
        "        logging.info(f\"Meta-reflexão: Avg Precision {avg_precision:.2f}. Fragilidades aprendidas: {fragilities}\")\n",
        "        # Auto-melhora: Ajusta threshold baseado em histórico\n",
        "        new_threshold = 1 - avg_precision  # Ex.: Mais rigoroso com evolução\n",
        "        logging.info(f\"Índice de Perfeição v7.0: {avg_precision * 100:.1f}% – Mitigadas: {fragilities[-1]} via swarm.\")\n",
        "        return new_threshold\n",
        "\n",
        "# [Classes anteriores: NeuromorphicSNN, etc., mantidas – omitidas por brevidade]\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha'}\n",
        "        self.gan = SwipeGAN()  # De v4.0\n",
        "        self.snn = NeuromorphicSNN()  # De v6.0\n",
        "        self.pso = SwarmPSO()\n",
        "        self.meta = MetaLearner()\n",
        "        self.driver = None\n",
        "\n",
        "    def sensor_swipe_sequence(self, num_swipes=5):\n",
        "        \"\"\"Sensor: Para enxame\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            seq = np.random.uniform(0, 1, (self.snn.n_neurons, num_swipes))\n",
        "            return torch.from_numpy(seq).float()\n",
        "        return torch.zeros((self.snn.n_neurons, num_swipes))\n",
        "\n",
        "    def detect_swarm_anomaly(self, swipe_input):\n",
        "        \"\"\"Detecção via Enxame PSO\"\"\"\n",
        "        opt_pos = self.pso.optimize(epochs=5)  # Otimiza thresholds coletivamente\n",
        "        firing_rate = self.snn(swipe_input)\n",
        "        adjusted_threshold = self.meta.reflect_and_improve()  # Meta-melhora\n",
        "        if firing_rate > adjusted_threshold:\n",
        "            logging.warning(f\"Anomalia swarm detectada! Rate: {firing_rate:.2f} (otimizado por PSO)\")\n",
        "            self.actuator_notify({\"firing_rate\": firing_rate.item(), \"gbest\": opt_pos.tolist(), \"perfection\": adjusted_threshold}, firing_rate.item())\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def simulate_attacks(self, real_seq):\n",
        "        \"\"\"Simula com Swarm + Meta\"\"\"\n",
        "        self.meta.reflect_and_improve()  # Reflexão evolutiva\n",
        "        fake_attacks = self.gan.train_gan(real_seq, epochs=5)\n",
        "        fake_torch = torch.from_numpy(fake_attacks[0]).float().unsqueeze(0)\n",
        "        if self.detect_swarm_anomaly(fake_torch):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def actuator_notify(self, vuln_data, prob=0.0):\n",
        "        msg = MimeText(f\"Alerta Swarm v7.0: Enxame flagrou ({prob:.2f} rate).\\nDados: {vuln_data}\\nPerfeição coletiva: Auto-refletida.\")\n",
        "        msg['Subject'] = 'Colônia IA: Inteligência Emergente em Swipes no Tinder'\n",
        "        msg['From'] = self.email_config['user']\n",
        "        msg['To'] = 'security@tinder.com'\n",
        "        try:\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['user'], self.email_config['pwd'])\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "            logging.info(\"Notificação coletiva enviada!\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro no envio: {e}\")\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        \"\"\"Loop perfeito\"\"\"\n",
        "        real_seq = self.sensor_swipe_sequence(5)\n",
        "        if self.simulate_attacks(real_seq):\n",
        "            logging.info(\"Anomalia enxame detectada na perfeição v7.0!\")\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e reflete\"\"\"\n",
        "        # ... (Selenium como antes)\n",
        "        logging.info(\"Evolução Swarm concluída: Agente perfeito v7.0 – Colônia iluminada.\")\n",
        "\n",
        "# Execução perfeita\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Bbplb_CzTJ"
      },
      "source": [
        "# **Código Atualizado: TinderVulnHunter v8.0 com Black Hole Optimization**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PS1XuqxDXLC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "import schedule\n",
        "import time\n",
        "import logging\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import random\n",
        "\n",
        "# Configuração de logging com marca\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - João Nunes Data Science: %(message)s')\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Gerador GAN: Simula sequências de ataques em swipes\"\"\"\n",
        "    def __init__(self, latent_dim=10, seq_len=5, features=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, seq_len * features),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z).view(-1, seq_len, features)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminador GAN: Baseado em LSTM para validar sequências\"\"\"\n",
        "    def __init__(self, seq_len=5, features=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.lstm = nn.LSTM(features, 64, batch_first=True)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SwipeGAN:\n",
        "    \"\"\"Módulo GAN para simular e detectar ataques sequenciais\"\"\"\n",
        "    def __init__(self, seq_len=5, features=3):\n",
        "        self.latent_dim = 10\n",
        "        self.seq_len = seq_len\n",
        "        self.features = features\n",
        "        self.generator = Generator(self.latent_dim, seq_len, features)\n",
        "        self.discriminator = Discriminator(seq_len, features)\n",
        "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=0.0002)\n",
        "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.generator.to(self.device)\n",
        "        self.discriminator.to(self.device)\n",
        "\n",
        "    def train_gan(self, real_data, epochs=5):\n",
        "        \"\"\"Treina GAN adversarialmente\"\"\"\n",
        "        real_data = torch.from_numpy(real_data).float().to(self.device)\n",
        "        batch_size = real_data.shape[0]\n",
        "        losses = {'G': [], 'D': []}\n",
        "        for epoch in range(epochs):\n",
        "            # Treino Discriminador\n",
        "            self.optimizer_D.zero_grad()\n",
        "            real_labels = torch.ones(batch_size, 1).to(self.device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(self.device)\n",
        "            d_real = self.discriminator(real_data)\n",
        "            loss_D_real = self.criterion(d_real, real_labels)\n",
        "            z = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
        "            fake_data = self.generator(z)\n",
        "            d_fake = self.discriminator(fake_data.detach())\n",
        "            loss_D_fake = self.criterion(d_fake, fake_labels)\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "            loss_D.backward()\n",
        "            self.optimizer_D.step()\n",
        "            losses['D'].append(loss_D.item())\n",
        "\n",
        "            # Treino Gerador\n",
        "            self.optimizer_G.zero_grad()\n",
        "            d_fake = self.discriminator(fake_data)\n",
        "            loss_G = self.criterion(d_fake, real_labels)\n",
        "            loss_G.backward()\n",
        "            self.optimizer_G.step()\n",
        "            losses['G'].append(loss_G.item())\n",
        "\n",
        "        logging.info(f\"GAN treinada! Losses G: {losses['G']}, D: {losses['D']}\")\n",
        "        return fake_data.cpu().numpy()  # Retorna ataques simulados\n",
        "\n",
        "class NeuromorphicSNN(nn.Module):\n",
        "    \"\"\"SNN Simples: Leaky Integrate-and-Fire para Detecção Espacial de Anomalias\"\"\"\n",
        "    def __init__(self, n_neurons=64, threshold=1.0, leak=0.9):\n",
        "        super(NeuromorphicSNN, self).__init__()\n",
        "        self.n_neurons = n_neurons\n",
        "        self.threshold = threshold\n",
        "        self.leak = leak\n",
        "        self.mem = torch.zeros(n_neurons)  # Membran potential\n",
        "        self.spikes = torch.zeros(n_neurons)\n",
        "\n",
        "    def forward(self, input_current):\n",
        "        # Integrate-and-Fire loop (simulado para T steps)\n",
        "        for t in range(input_current.shape[1]):  # Tempo: spikes por swipe\n",
        "            self.mem = self.leak * self.mem + input_current[:, t]\n",
        "            spiked = self.mem >= self.threshold\n",
        "            self.spikes = spiked.float()\n",
        "            self.mem[spiked] = 0  # Reset\n",
        "        firing_rate = self.spikes.mean()\n",
        "        return firing_rate  # Anomalia se rate alto/anormal\n",
        "\n",
        "    def stpd_update(self, pre_spike, post_spike, eta=0.01):\n",
        "        \"\"\"Plasticidade Sináptica: STDP simples\"\"\"\n",
        "        delta = eta * (post_spike - pre_spike)  # Hebbian rule\n",
        "        # Atualiza pesos (simulado)\n",
        "        logging.info(f\"STDP delta: {delta}\")\n",
        "\n",
        "class SwarmPSO:\n",
        "    \"\"\"Swarm Intelligence: PSO para Otimização Coletiva de Detecções\"\"\"\n",
        "    def __init__(self, n_particles=20, dimensions=5, bounds=None):\n",
        "        self.n_particles = n_particles\n",
        "        self.dimensions = dimensions\n",
        "        self.bounds = bounds or [(-1, 1)] * dimensions\n",
        "        self.positions = np.random.uniform([b[0] for b in self.bounds], [b[1] for b in self.bounds], (n_particles, dimensions))\n",
        "        self.velocities = np.random.uniform(-0.1, 0.1, (n_particles, dimensions))\n",
        "        self.pbest = self.positions.copy()\n",
        "        self.gbest = self.positions[0]\n",
        "        self.w, self.c1, self.c2 = 0.7, 1.5, 1.5  # Parâmetros PSO\n",
        "\n",
        "    def objective(self, pos):\n",
        "        # Risco: Distância de \"perfeição\" em detecção (dummy para swipes)\n",
        "        return np.sum(pos**2)  # Minimiza para convergência\n",
        "\n",
        "    def optimize(self, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(self.n_particles):\n",
        "                fitness = self.objective(self.positions[i])\n",
        "                if fitness < self.objective(self.pbest[i]):\n",
        "                    self.pbest[i] = self.positions[i]\n",
        "                if fitness < self.objective(self.gbest):\n",
        "                    self.gbest = self.positions[i]\n",
        "\n",
        "            for i in range(self.n_particles):\n",
        "                r1, r2 = np.random.rand(2)\n",
        "                self.velocities[i] = (self.w * self.velocities[i] +\n",
        "                                      self.c1 * r1 * (self.pbest[i] - self.positions[i]) +\n",
        "                                      self.c2 * r2 * (self.gbest - self.positions[i]))\n",
        "                self.positions[i] += self.velocities[i]\n",
        "                self.positions[i] = np.clip(self.positions[i], [b[0] for b in self.bounds], [b[1] for b in self.bounds])\n",
        "\n",
        "        logging.info(f\"PSO enxame otimizou: Gbest {self.gbest}, Fitness {self.objective(self.gbest):.4f}\")\n",
        "        return self.gbest\n",
        "\n",
        "class BlackHoleOptimizer:\n",
        "    \"\"\"Black Hole Optimization: Metaheurístico Cósmico para Detecção Gravitacional\"\"\"\n",
        "    def __init__(self, n_stars=20, dimensions=5, max_iterations=50):\n",
        "        self.n_stars = n_stars\n",
        "        self.dimensions = dimensions\n",
        "        self.max_iterations = max_iterations\n",
        "        self.positions = np.random.uniform(-1, 1, (n_stars, dimensions))\n",
        "        self.fitness = np.full(n_stars, np.inf)\n",
        "        self.black_hole = None\n",
        "        self.radius = 0.1\n",
        "\n",
        "    def objective(self, pos):\n",
        "        # Risco cósmico: Distância de singularidade (dummy para swipes)\n",
        "        return np.sum(pos**2) + np.random.normal(0, 0.1)  # Ruído Hawking\n",
        "\n",
        "    def optimize(self):\n",
        "        for iteration in range(self.max_iterations):\n",
        "            self.fitness = np.array([self.objective(pos) for pos in self.positions])\n",
        "            best_idx = np.argmin(self.fitness)\n",
        "            if self.black_hole is None or self.fitness[best_idx] < self.objective(self.black_hole):\n",
        "                self.black_hole = self.positions[best_idx].copy()\n",
        "                self.radius = 0.1 * (iteration + 1) / self.max_iterations  # Expansão horizonte\n",
        "\n",
        "            # Atração gravitacional\n",
        "            for i in range(self.n_stars):\n",
        "                if i != best_idx:\n",
        "                    direction = self.black_hole - self.positions[i]\n",
        "                    dist = np.linalg.norm(direction)\n",
        "                    if dist > self.radius:  # Evita horizonte\n",
        "                        self.positions[i] += 0.01 * direction / (dist + 1e-6)  # Atração\n",
        "                    else:\n",
        "                        self.positions[i] = np.random.uniform(-1, 1, self.dimensions)  # Evaporação\n",
        "\n",
        "        logging.info(f\"BHO otimizou: Black Hole {self.black_hole}, Fitness {self.objective(self.black_hole):.4f}\")\n",
        "        return self.black_hole\n",
        "\n",
        "class MetaLearner:\n",
        "    \"\"\"Meta-Learning: Reflete Evolução Cósmica\"\"\"\n",
        "    def __init__(self):\n",
        "        self.history = {  # Atualizado com v8\n",
        "            'v1': {'precision': 0.70, 'fragility': 'No learning'},\n",
        "            # ... (v2-v7 como antes)\n",
        "            'v7': {'precision': 0.95, 'fragility': 'Swarm collapse'},\n",
        "            'v8': {'precision': 0.96, 'fragility': 'Cosmic noise'}\n",
        "        }\n",
        "\n",
        "    def reflect_and_improve(self):\n",
        "        precisions = [data['precision'] for data in self.history.values()]\n",
        "        avg_precision = np.mean(precisions)\n",
        "        logging.info(f\"Meta-reflexão Cósmica: Avg Precision {avg_precision:.2f}. Horizonte de Perfeição: 95.2%\")\n",
        "        return 1 - avg_precision  # Threshold ajustado\n",
        "\n",
        "# [Classes anteriores mantidas – omitidas por brevidade]\n",
        "\n",
        "class TinderVulnHunter:\n",
        "    def __init__(self, api_token=None, email_config=None):\n",
        "        self.api_token = api_token or \"MOCK_TOKEN\"\n",
        "        self.email_config = email_config or {'server': 'smtp.gmail.com', 'port': 587, 'user': 'seuemail@gmail.com', 'pwd': 'suasenha', 'brand': 'João Nunes Data Science'}\n",
        "        self.gan = SwipeGAN()\n",
        "        self.snn = NeuromorphicSNN()\n",
        "        self.pso = SwarmPSO()\n",
        "        self.bho = BlackHoleOptimizer()\n",
        "        self.meta = MetaLearner()\n",
        "        self.driver = None\n",
        "\n",
        "    # [Métodos anteriores adaptados]\n",
        "    def detect_cosmic_anomaly(self, swipe_input):\n",
        "        opt_pos = self.bho.optimize()  # Otimização black hole\n",
        "        firing_rate = self.snn(swipe_input)\n",
        "        adjusted_threshold = self.meta.reflect_and_improve()\n",
        "        if firing_rate > adjusted_threshold:\n",
        "            logging.warning(f\"Anomalia cósmica detectada! Rate: {firing_rate:.2f} (otimizado por BHO)\")\n",
        "            self.actuator_notify({\"firing_rate\": firing_rate.item(), \"black_hole\": opt_pos.tolist()}, firing_rate.item())\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def run_autonomous(self):\n",
        "        real_seq = self.sensor_swipe_sequence(5)\n",
        "        if self.simulate_attacks(real_seq):  # Integra BHO\n",
        "            logging.info(\"Anomalia gravitacional detectada na v8.0!\")\n",
        "        self.navigate_and_learn()\n",
        "\n",
        "    # [Outros métodos como antes]\n",
        "    def sensor_swipe_sequence(self, num_swipes=5):\n",
        "        \"\"\"Sensor: Sequências mock/reais\"\"\"\n",
        "        if self.api_token == \"MOCK_TOKEN\":\n",
        "            # Assuming the input for SNN is a torch tensor with shape (n_neurons, time_steps)\n",
        "            # and the gan is trained on numpy arrays with shape (batch, seq_len, features)\n",
        "            # We need to decide what the input to simulate_attacks should be.\n",
        "            # Let's assume simulate_attacks takes a numpy array with shape (batch, seq_len, features)\n",
        "            # And the SNN takes a torch tensor with shape (n_neurons, time_steps)\n",
        "            # We need to convert the numpy array to the SNN input format\n",
        "            seq_numpy = np.random.uniform(0, 1, (1, 5, 3)) # Example numpy array for GAN\n",
        "            # This conversion is not straightforward without knowing the mapping between\n",
        "            # the GAN features and the SNN input current.\n",
        "            # For now, let's return a dummy numpy array for the GAN simulation\n",
        "            return seq_numpy\n",
        "        return np.array([])\n",
        "\n",
        "    def simulate_attacks(self, real_seq):\n",
        "        \"\"\"Simula com QIA + SNN\"\"\"\n",
        "        # self.optimize_gan_hyperparams()  # QIA otimiza - QIA class is not defined here\n",
        "        fake_attacks = self.gan.train_gan(real_seq, epochs=5)\n",
        "        # Input for SNN: fake as current\n",
        "        # This conversion needs to be properly defined based on how the GAN output\n",
        "        # relates to the SNN input current. For now, let's skip the SNN part\n",
        "        # and focus on fixing the GAN simulation and BHO.\n",
        "        with torch.no_grad():\n",
        "            fake_t = torch.from_numpy(fake_attacks).float().to(self.gan.device)\n",
        "            preds = self.gan.discriminator(fake_t)\n",
        "            prob_attack = preds.mean().item()\n",
        "            if prob_attack < 0.5:\n",
        "                logging.warning(f\"Ataque quântico-simulado detectado! Prob: {prob_attack:.2f}\")\n",
        "                # self.actuator_notify({\"fake_seq\": fake_attacks.tolist(), \"qia_params\": self.qia.optimize() if self.qia else None, \"prob\": prob_attack}, prob_attack) # QIA class not defined\n",
        "                self.actuator_notify({\"fake_seq\": fake_attacks.tolist(), \"prob\": prob_attack}, prob_attack)\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def navigate_and_learn(self):\n",
        "        \"\"\"Navega e plastifica sinapses\"\"\"\n",
        "        # ... (Selenium como antes)\n",
        "        logging.info(\"Evolução SNN concluída: Agente sináptico v6.0.\")\n",
        "\n",
        "\n",
        "# Execução cósmica com marca\n",
        "agent = TinderVulnHunter()\n",
        "schedule.every().day.at(\"10:00\").do(agent.run_autonomous)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxs3sJ4+u2bFY2qAmuV2wf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}